{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA0FNjvD1ssq",
        "outputId": "b98084de-797a-47a4-bc2b-67a43b02fe41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_add.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile vector_add.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <cstdio> // Required for printf\n",
        "\n",
        "__global__ void vectorAdd(const float* A, const float* B, float* C, int N) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < N) {\n",
        "        C[i] = A[i] + B[i];\n",
        "        printf(\"Thread %d: %f + %f = %f\\n\", i, A[i], B[i], C[i]);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 10;\n",
        "    float A[N], B[N], C[N];\n",
        "\n",
        "    // Initialize host arrays (example values)\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        A[i] = i + 1.0f;\n",
        "        B[i] = i * 2.0f;\n",
        "    }\n",
        "\n",
        "    float *d_a, *d_b,*d_c;\n",
        "    cudaMalloc(&d_a,N*sizeof(float));\n",
        "    cudaMalloc(&d_b,N*sizeof(float));\n",
        "    cudaMalloc(&d_c,N*sizeof(float));\n",
        "    cudaMemcpy(d_a,A,N*sizeof(float),cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b,B,N*sizeof(float),cudaMemcpyHostToDevice);\n",
        "\n",
        "    int blocksize = 256;\n",
        "    int gridsize = (N + blocksize - 1) / blocksize; // Calculate grid size correctly\n",
        "\n",
        "    printf(\"Launching kernel with grid size %d and block size %d\\n\", gridsize, blocksize);\n",
        "\n",
        "    vectorAdd<<<gridsize,blocksize>>>(d_a,d_b,d_c,N);\n",
        "\n",
        "    cudaMemcpy(C,d_c,N*sizeof(float),cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Results from device:\\n\");\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        printf(\"C[%d] = %f\\n\", i, C[i]);\n",
        "    }\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    return 0; // Added return 0 for main\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile with the specified architecture\n",
        "!nvcc vector_add.cu -o vector_add -gencode arch=compute_75,code=sm_75\n",
        "\n",
        "# Run the executable\n",
        "!./vector_add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pk9GewMY1zt7",
        "outputId": "1710048b-04a1-4dd6-ce4a-bf80e9ec1390"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching kernel with grid size 1 and block size 256\n",
            "Results from device:\n",
            "C[0] = 0.000000\n",
            "C[1] = 0.000000\n",
            "C[2] = 0.000000\n",
            "C[3] = 0.000000\n",
            "C[4] = 0.000000\n",
            "C[5] = 0.000000\n",
            "C[6] = 0.000000\n",
            "C[7] = 0.000000\n",
            "C[8] = 0.000000\n",
            "C[9] = 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ywRE2W4w18DA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}